{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Data Parsing (flatten JSON to csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the JSON data\n",
    "data_folder = \"../SGNexData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SGNexData/Hct116R4R3.json\n",
      "../SGNexData/HepG2R5R2.json\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        #Construct full path for each JSON file\n",
    "        json_file_path = os.path.join(data_folder,filename)\n",
    "        data = []\n",
    "    \n",
    "        with open(json_file_path, 'r') as json_file:\n",
    "            for line in json_file:\n",
    "                if line.strip(): #Skip empty lines\n",
    "                    data.append(json.loads(line))\n",
    "        \n",
    "        #Prepare a list to store the flattened data\n",
    "        flattened_data = []\n",
    "\n",
    "        #Iterate through loaded data\n",
    "        for entry in data:\n",
    "            for enst_id, positions in entry.items():\n",
    "                    for position, sub_dict in positions.items():\n",
    "                            for key, values in sub_dict.items():\n",
    "                                        # Store the entire list of values as a string\n",
    "                                        row = {\n",
    "                                                'ENST_ID': enst_id,\n",
    "                                                'Position': position,\n",
    "                                                'Key': key,\n",
    "                                                'Values': str(values)  # Store the list as a string\n",
    "                                        }\n",
    "                                        flattened_data.append(row)\n",
    "                                        \n",
    "        # Convert the list of dictionaries to a DataFrame\n",
    "        df = pd.DataFrame(flattened_data)\n",
    "        \n",
    "        #Save the DataFrame to a CSV file\n",
    "        csv_file_name = filename.replace('.json','.csv') #Change file extention from .json to .csv\n",
    "        csv_file_path = os.path.join(data_folder,csv_file_name)\n",
    "\n",
    "        df.to_csv(csv_file_path, index=False) #Save df to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def calculate_average(values):\n",
    "    arr = np.array(values)\n",
    "    return arr.mean(axis=0).tolist()\n",
    "\n",
    "def convert_to_float(value):\n",
    "        value = eval(value)\n",
    "        return [[float(elem) for elem in inner] for inner in value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SGNexData/HepG2R5R2.csv\n",
      "../SGNexData/Hct116R4R3.csv\n",
      "../SGNexData/K562R5R1.csv\n",
      "../SGNexData/Hct116R3R4.csv\n",
      "../SGNexData/HepG2R6R1.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith('.csv'):\n",
    "        #Construct full path for each dataframe\n",
    "        df_file_path = os.path.join(data_folder,filename)\n",
    "        print(df_file_path)\n",
    "        df = pd.read_csv(df_file_path)\n",
    "\n",
    "        # Convert values from str to float\n",
    "        df['Values'] = df['Values'].apply(convert_to_float)\n",
    "\n",
    "        # Get the avg of all values\n",
    "        df['Values'] = df['Values'].apply(calculate_average)\n",
    "\n",
    "        # Split values into individual columns\n",
    "        values_expanded = df['Values'].apply(pd.Series)\n",
    "        values_expanded.columns = [f'Value_{i+1}' for i in range(values_expanded.shape[1])]\n",
    "        clean_df = pd.concat([df, values_expanded], axis=1)\n",
    "        clean_df.drop(columns=['Values'], inplace=True)\n",
    "\n",
    "        # Shuffle the entire dataset\n",
    "        clean_df = clean_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        # Convert strings to numerical value\n",
    "        label_encoder = LabelEncoder()\n",
    "        clean_df['ENST_ID_encoded'] = label_encoder.fit_transform(clean_df['ENST_ID'])\n",
    "        clean_df['Key_encoded'] = label_encoder.fit_transform(clean_df['Key'])\n",
    "\n",
    "        #convert to csv\n",
    "        csv_file_name, file_extension = os.path.splitext(df_file_path)\n",
    "        new_file_path = f\"{csv_file_name}_processed{file_extension}\"\n",
    "        clean_df.to_csv(new_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
